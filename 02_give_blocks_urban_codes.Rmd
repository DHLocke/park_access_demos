---
title: "give_blocks_urban_codes"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 0 load libraries, get oriented

```{r}
# Load libraries 
packs <-c(  'tidyverse' # cuz
          , 'tidylog'   # prints out what was done in dplyr and tidyr; VERBOSE
          , 'magrittr'  # for all of the the pipes
          , 'sf'        # for spatial data support
          # , 'sp'        #  older spatial data support
          # , 'spdep'     # spatial dependency
          # , 'sfdep'     # remotes::install_github("josiahparry/sfdep")
          , 'mapview'   # web maps for zooming and panning around
          , 'beepr'     # makes noises
          , 'tictoc'    # times things
          , 'tigris'    # Census geographic data (via TIGER)
          # , 'parallel'  # parallel processing, vroom, vroom
          )

if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))
}

# load the packages all at once
vapply(packs, library, character.only = TRUE, logical(1),
       logical.return = TRUE, quietly = TRUE)

# get oriented
list.files()
list.files('input_data')


# for reproducibility
set.seed(19870630)

# fixes mapview
mapviewOptions(fgb = FALSE)
# mapviewOptions(platform = "leafgl") #should help with large data.

# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# # Paralise any simple features analysis.
# # https://www.spatialanalytics.co.nz/post/2017/09/11/a-parallel-function-for-spatial-analysis-in-r/
# # define
# st_par <- function(sf_df, sf_func, n_cores, ...){
# 
#   # Create a vector to split the data set up by.
#   split_vector <- rep(1:n_cores, each = nrow(sf_df) / n_cores, length.out = nrow(sf_df))
# 
#   # Perform GIS analysis
#   split_results <- split(sf_df, split_vector) %>%
#     mclapply(function(x) sf_func(x, ...), mc.cores = n_cores)
# 
#   # Combine results back together. Method of combining depends on the output from the function.
#   if (class(split_results[[1]]) == 'list' ){
#     result <- do.call("c", split_results)
#     names(result) <- NULL
#   } else {
#     result <- do.call("rbind", split_results)
#   }
# 
#   # Return result
#   return(result)
# }
# 
# # Paralise any simple features analysis.
# # https://www.spatialanalytics.co.nz/post/2018/04/01/fixing-st-par/
# # define
# st_parallel <- function(sf_df, sf_func, n_cores, ...){
# 
#   # Create a vector to split the data set up by.
#   split_vector <- rep(1:n_cores, each = nrow(sf_df) / n_cores, length.out = nrow(sf_df))
# 
#   # Perform GIS analysis
#   split_results <- split(sf_df, split_vector) %>%
#     parallel::mclapply(function(x) sf_func(x, ...), mc.cores = n_cores)
#   
#   
#   # Define the output_class. If length is greater than two, then grab the second variable.
#   output_class <- class(split_results[[1]])
#   if (length(output_class) == 2){
#     output_class <- output_class[2]
#   }
#   
#   # Combine results back together. Method of combining depends on the output from the function.
#   if (output_class == "matrix"){
#     result <- do.call("rbind", split_results)
#     names(result) <- NULL
#   } else if (output_class == "sfc") {
#     result <- do.call("c", split_results)
#     result <- sf_func(result) # do.call combines the list but there are still n_cores of the geometry which had been split up. Running st_union or st_collect gathers them up into one, as is the expected output of these two functions. 
#   } else if (output_class %in% c('list', 'sgbp') ){
#     result <- do.call("c", split_results)
#     names(result) <- NULL
#   } else if (output_class == "data.frame" ){
#     result <- do.call("rbind", split_results)
#   } else {
#     stop("Unknown class. st_parallel only accepts the following outputs at present: sfc, list, sf, matrix, sgbp.")
#   }
#   
#   # Return result
#   return(result)
# }

```


## handy stuff
## spatial objects
```{r}
# see_sf() -> sf_in_memory; mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()
see_sf() -> sf_in_memory; mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$input) %>% unlist() #%>% View()
```

## print size of each object
```{r}
for(obj in ls()){message(obj); print(object.size(get(obj)), units='auto'); cat('\n')}; rm(obj)
```



# 1 read in urban areas polygons
```{r}

(ua <- st_read('input_data/Urban Areas/Urban Areas- US Census - 2018 - crs102039.shp') |> 
   select(UACE10, UA_name = NAME10))

# mapview(ua)

# dim(ua)
# ua |> st_drop_geometry() |> distinct(UACE10) |> dim()
```



# 2 Blocks (spatial) - get centroid, intersect, write out.
```{r}

# this will be the iterator for querying states
(state_codes <- read_csv('input_data/ws_cty_int_lookup_batch_size_850_2022-04-27.csv') |> 
  distinct(stcode, st) |> 
  arrange(stcode))


combined_layer <- '/Users/dlocke/SESYNC/sesync_greenspace/park_access/park_access_demos/input_data/combined_blocks_2020_no_water_single_part/combined_blocks_2020_no_water_single_part.gpkg'


(query_start <- 'SELECT * FROM "combined_blocks_2020_no_water_single_part" WHERE stcode = ')



tic(); for(i in state_codes$stcode){ # loop through each state code
  tic() # iteration clock in
  # cat('working on sesync_id:', i, '\n')
  cat('\n working on batch:', i, '\n')
  
  # read in only the polygons of ith state
  i_layer <- st_read(
    combined_layer
    , query = paste0(query_start, "\"", i, "\"") # SQL in R is strange because of special chars..
    , as_tibble = TRUE) |>
    st_make_valid() |> 
    st_transform(crs = st_crs(ua)) |> 
    st_centroid() |> 
    st_intersection(ua) |> 
    st_drop_geometry() |> 
    select(mult_id, GISJOIN, UACE10, UA_name) |> # use these names on import!
    write_csv(file = paste0(getwd(),
                            '/input_data/combined_blocks_2020_no_water_single_part_Urban_Area_lookup/block_to_ua_lookup.csv'
    )
    , append = TRUE
    , progress = TRUE)
  cat('intersect duration: ')
  toc()  # clock out of the i-th iteration
  beepr::beep()
}; toc() # end loop and clock out ~ 4 hrs

 
```


## save out

```{r eval=FALSE, include=FALSE}
# save.image("saved_sessions/02_give_blocks_urban_codes.RData") 
```


## CITE your sources!!!

```{r}
lapply(packs, citation); rm(packs)
sessionInfo()
```

Last Knit on `r format(Sys.time())`

# SANDBOX
```{r}

```

